#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
File that generates the complete database
"""

from __future__ import print_function
from rdkit import Chem
from rdkit.Chem import AllChem

import os
import pandas as pd
import numpy as np
import multiprocessing
from math import pow, log
import pickle
np.random.seed(1342341)

"""
DATASETS
"""


#Count number of processors of server
cpus = multiprocessing.cpu_count()

dataset_file= "Complete_dataset_without_duplicates.csv"
modeldir = "kernel_ridge_regression/"
nestimators = int(pow(2,18)) #Deepchem with 1024=2^10 results in 0.97/0.94
fbits = 13 #2^fbits Bits in fingerprint. Deepchem has 2048 = 2^11
radius =3 #Fingerprint radius. Deehcpem has 2
train_perc = 0.6 #percent of data in train set. Deepchem has 0.8
logs_limit = log(0.3, 10)

#Create directory if not exists
if not os.path.exists(modeldir):
    os.makedirs(modeldir)


#Import database
database = pd.read_csv(dataset_file)

#Associate molecule to each smile and create fingerprint
mols = [Chem.MolFromSmiles(x) for x in  database["smiles"]]

#Get the fingerprints for the mols (same fingerprints as deepchem)
fmols = [AllChem.GetMorganFingerprintAsBitVect(mol = x, 
                                               radius = int(radius), 
                                               useChirality = False, 
                                               useBondTypes = True,
                                               useFeatures = False,
                                               nBits = int(pow(2, fbits))) for x in mols]
string_fpints = [x.ToBitString() for x in fmols]

#Add fingerprint to database
fpints = [np.array(list(x))  for x in string_fpints]
database =  pd.concat([database.reset_index(drop=True), pd.DataFrame(fpints)], axis=1)

database["Classification"] = True
database["Classification"] = [(x > logs_limit) for x in database["logS"]]

# Split the data into training and testing sets
train, validate, test = np.split(database.sample(frac=1), [int(train_perc*len(database)), int((0.5 + train_perc/2)*len(database))])

#Run Sci-Kit learn
from sklearn.kernel_ridge import KernelRidge

# Instantiate model with nestimators decision trees
kr = KernelRidge(kernel="rbf", alpha=1, gamma=0.05)
kr.fit(train.drop(["smiles", "logS","Classification"], axis=1), train["logS"])

# Use the forest's predict method on the test data
predictions_test   = [(x > logs_limit) for x in kr.predict(test.drop(["smiles", "logS","Classification"], axis = 1))]
predictions_train  = [(x > logs_limit) for x in kr.predict(train.drop(["smiles", "logS","Classification"], axis = 1))]
predictions_valid  = [(x > logs_limit) for x in kr.predict(validate.drop(["smiles", "logS","Classification"], axis = 1))]

#Get r^2
from sklearn.metrics import precision_score
ptrain = precision_score(predictions_train, train["Classification"])
ptest  = precision_score(predictions_test, test["Classification"])
pvalid = precision_score(predictions_valid, validate["Classification"])
print('Train Sklearn precision:', round(ptrain, 2))
print('Pred Sklearn precision:', round(ptest,2))
print('Validate Sklearn precision:', round(pvalid , 2))


with open('kernel_ridge_regression.pickle', 'wb') as f:
    pickle.dump(kr, f)



data = {'KernelRidgeRegression':['Train', 'Test', 'Validate'], 'Precision':[ptrain, ptest, pvalid]} 
data = pd.DataFrame(data)
data.to_csv("Precision_KernelRidgeRegression.csv")

try:
    from notifyending import notify_ending
    notify_ending("Finished fitting KRR")
except:
    print("krr")

#quit()
